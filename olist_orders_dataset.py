# -*- coding: utf-8 -*-
"""Olist-orders-dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IBS3gjF6JXzi7Fm5ErPp7M5hzGyiQmna
"""

# Import the pandas library with the alias 'pd'
import pandas as pd

# Import the pandas library with the alias 'pd'
import pandas as pd

# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„Ù
orders= pd.read_csv("olist_orders_dataset.csv")
print(orders)

"""## **Exploring Data**"""

orders.head()

orders.tail()

print(orders.info())

print(orders.describe())

orders.shape

print("Missing values per column:\n", orders.isnull().sum())

orders.isnull().sum().sum()

orders.duplicated()

orders.duplicated().sum()

"""## **Cleaning Data**"""

# ØªØµÙÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­ÙŠØ« ØªÙˆØ¬Ø¯ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
missing_dates_orders = orders[orders[['order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date']].isnull().any(axis=1)]

# Ø¹Ø±Ø¶ ØªÙˆØ²ÙŠØ¹ Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ù„Ø¨ Ù„Ù‡Ø°Ù‡ Ø§Ù„ØµÙÙˆÙ
print(missing_dates_orders['order_status'].value_counts())

# Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 10 ØµÙÙˆÙ Ø¨Ù‡Ø§ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
print(missing_dates_orders[['order_status', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date']].head(10))

# Ù„Ù†ÙØªØ±Ø¶ Ø£Ù† Ù„Ø¯ÙŠÙƒ DataFrame Ø§Ø³Ù…Ù‡ orders
# ÙˆÙ†Ø±ÙŠØ¯ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø«Ù„Ø§Ø«Ø© Ø£Ø¹Ù…Ø¯Ø© Ø²Ù…Ù†ÙŠØ©:
date_cols = ['order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date']

# Ù†Ø±ÙŠØ¯ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ:
# 1. Ø­Ø§Ù„ØªÙ‡Ø§ delivered
# 2. ÙŠÙˆØ¬Ø¯ ÙÙŠÙ‡Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ù‚ÙŠÙ…Ø© Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ Ø£ÙŠ Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©

delivered_with_null = df[
    (orders['order_status'] == 'delivered') &
    (orders[date_cols].isnull().any(axis=1))
]

# Ø¹Ø±Ø¶ Ù‡Ø°Ù‡ Ø§Ù„ØµÙÙˆÙ
print(delivered_with_null)

"""##  olist_order_items_dataset"""

# Import the pandas library with the alias 'pd'
import pandas as pd

# Import the pandas library with the alias 'pd'
import pandas as pd

# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„Ù
items = pd.read_csv("olist_order_items_dataset.csv")
print(items)

items.head()

items.tail()

items.describe()

items.info()

items.duplicated().sum()

items.isnull().sum()

items.isnull().sum().sum()

#OUTLIERS
import pandas as pd

# Assuming your DataFrame is named 'df'
# and the column you want to analyze is 'price'

# Calculate quantiles
Q1 = items['price'].quantile(0.25)
Q3 = items['price'].quantile(0.75)
IQR = Q3 - Q1

# Define upper and lower bounds for outliers
lower_limit = Q1 - 1.5 * IQR
upper_limit = Q3 + 1.5 * IQR

# Identify outliers
outliers = items[(items['price'] < lower_limit) | (items['price'] > upper_limit)]

# Get unique product IDs with outliers
products_with_outliers = outliers['product_id'].unique()

# Count the number of products with outliers
num_products_with_outliers = len(products_with_outliers)

# Print the result
print(f"Number of products with outliers in 'price': {num_products_with_outliers}")

import pandas as pd

# Assuming your DataFrame is named 'df'
# Replace 'price' with the actual column name you want to analyze

def highlight_outliers(s):
    '''
    Highlight the outliers in a Series yellow.
    '''
    is_outlier = (s < lower_limit) | (s > upper_limit)  # condition for outliers

    return ['background-color: yellow' if v else '' for v in is_outlier]


# Calculate quantiles
Q1 = items['price'].quantile(0.25) # Changed 'column_name' to 'price'
Q3 = items['price'].quantile(0.75) # Changed 'column_name' to 'price'
IQR = Q3 - Q1

# Define upper and lower bounds for outliers
lower_limit = Q1 - 1.5 * IQR
upper_limit = Q3 + 1.5 * IQR

# Apply styling to highlight outliers
styled_items = items.style.apply(highlight_outliers, subset=['price']) # Changed 'column_name' to 'price'

# Display the styled DataFrame with highlighted outliers
display(styled_items)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming your DataFrame is named 'df'
# and the column you want to analyze is 'price'

# Calculate quantiles
Q1 = items['price'].quantile(0.25)
Q3 = items['price'].quantile(0.75)
IQR = Q3 - Q1

# Define upper and lower bounds for outliers
lower_limit = Q1 - 1.5 * IQR
upper_limit = Q3 + 1.5 * IQR

# Identify outliers
outliers = items[(items['price'] < lower_limit) | (df['price'] > upper_limit)]

# Create a box plot to visualize outliers
plt.figure(figsize=(8, 6))
sns.boxplot(x=items['price'])
plt.title('Box Plot of Price with Outliers')
plt.xlabel('Price')
plt.show()
# Print some information about the outliers
print(f"Number of outliers: {len(outliers)}")
print(f"Lower limit: {lower_limit}")
print(f"Upper limit: {upper_limit}")

# Create a scatter plot to visualize outliers
plt.figure(figsize=(8, 6))
plt.scatter(items.index, items['price'], color='blue', label='Normal Data')
plt.scatter(outliers.index, outliers['price'], color='red', label='Outliers')
plt.title('Scatter Plot of Price with Outliers')
plt.xlabel('Index')
plt.ylabel('Price')
plt.legend()
plt.show()

# Print some information about the outliers
print(f"Number of outliers: {len(outliers)}")
print(f"Lower limit: {lower_limit}")
print(f"Upper limit: {upper_limit}")

#OUTLIERS
import pandas as pd

# Assuming your DataFrame is named 'df'
# and the column you want to analyze is 'freight_value'

# Calculate quantiles
Q1 = items['freight_value'].quantile(0.25)
Q3 = items['freight_value'].quantile(0.75)
IQR = Q3 - Q1

# Define upper and lower bounds for outliers
lower_limit = Q1 - 1.5 * IQR
upper_limit = Q3 + 1.5 * IQR

# Identify outliers
outliers = items[(items['freight_value'] < lower_limit) | (df['freight_value'] > upper_limit)]

# Get unique product IDs with outliers
products_with_outliers = outliers['product_id'].unique()

# Count the number of products with outliers
num_products_with_outliers = len(products_with_outliers)

# Print the result
print(f"Number of products with outliers in 'freight_value': {num_products_with_outliers}")

import pandas as pd

# Assuming your DataFrame is named 'df'
# Replace 'price' with the actual column name you want to analyze

def highlight_outliers(s):
    '''
    Highlight the outliers in a Series yellow.
    '''
    is_outlier = (s < lower_limit) | (s > upper_limit)  # condition for outliers

    return ['background-color: red' if v else '' for v in is_outlier]


# Calculate quantiles
Q1 = items['freight_value'].quantile(0.25) # Changed 'column_name' to 'price'
Q3 = items['freight_value'].quantile(0.75) # Changed 'column_name' to 'price' and Removed the tab character
IQR = Q3 - Q1

# Define upper and lower bounds for outliers
lower_limit = Q1 - 1.5 * IQR
upper_limit = Q3 + 1.5 * IQR

# Apply styling to highlight outliers
styled_df = items.style.apply(highlight_outliers, subset=['freight_value']) # Changed 'column_name' to 'price' to 'freight_value' to match the analysis

# Display the styled DataFrame with highlighted outliers
display(styled_items)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming your DataFrame is named 'df'
# and the column you want to analyze is 'freight_value'

# Calculate quantiles
Q1 = items['freight_value'].quantile(0.25)
Q3 = items['freight_value'].quantile(0.75)
IQR = Q3 - Q1

# Define upper and lower bounds for outliers
lower_limit = Q1 - 1.5 * IQR
upper_limit = Q3 + 1.5 * IQR

# Identify outliers
outliers = items[(df['freight_value'] < lower_limit) | (df['freight_value'] > upper_limit)]

# Create a scatter plot to visualize outliers
plt.figure(figsize=(10, 6))  # Adjust figure size if needed
plt.scatter(items.index, df['freight_value'], color='blue', label='Normal Data', alpha=0.5) # alpha for transparency
plt.scatter(outliers.index, outliers['freight_value'], color='red', label='Outliers', alpha=0.8)
plt.title('Scatter Plot of Freight Value with Outliers')
plt.xlabel('Index')
plt.ylabel('Freight Value')
plt.legend()
plt.grid(True)  # Add a grid for better readability
plt.show()

"""## olist_customers_dataset"""

# Import the pandas library with the alias 'pd'
import pandas as pd

# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„Ù
customers = pd.read_csv("olist_customers_dataset.csv")
print(customers)

customers.head()

customers.describe()

customers.info()

customers.duplicated().sum()

customers.isnull().sum()

customers.isnull().sum().sum()

customers.shape

num_customers = customers['customer_id'].nunique()
print(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡: {num_customers}")

num_cities = customers['customer_city'].nunique()
print(f"Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¯Ù†: {num_cities}")

num_zip_codes = customers['customer_zip_code_prefix'].nunique()
print(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø§ÙƒÙˆØ§Ø¯: {num_zip_codes}")

top_10_cities = customers['customer_city'].value_counts().head(10)
print(top_10_cities)

import matplotlib.pyplot as plt

# Calculate the top 10 customer cities
top_10_cities = customers['customer_city'].value_counts().head(10)

# Create the horizontal bar chart
plt.figure(figsize=(12, 6))  # Set the figure size
plt.barh(top_10_cities.index, top_10_cities.values)  # Create the horizontal bar chart
plt.xlabel("Number of Customers")  # Label the x-axis
plt.ylabel("City")  # Label the y-axis
plt.title("Top 10 Customer Cities")  # Set the title

# Add values to the bars
for i, v in enumerate(top_10_cities.values):
    plt.text(v + 3, i, str(v), color='black', fontweight='bold', va='center')

plt.tight_layout()  # Adjust the layout
plt.show()  # Display the chart

"""## olist_order_payments_dataset"""

import pandas as pd
# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„Ù
payments = pd.read_csv("olist_order_payments_dataset.csv")
print(payments)

payments.head()

payments.describe()

payments.info()

payments.duplicated().sum()

payments.isnull().sum()

num_payment_types = payments['payment_type'].nunique()
print(f"num_payment_types: {num_payment_types}")

payment_types = payments['payment_type'].unique()
print("Payment Types:", payment_types)

# To get the count of each payment type:
payment_type_counts = payments['payment_type'].value_counts()
print("\nPayment Type Counts:\n", payment_type_counts)

import matplotlib.pyplot as plt
import numpy as np

# ... (previous code to get payment_type_counts) ...

# Create a bar chart
plt.figure(figsize=(8, 6))
bars = plt.bar(payment_type_counts.index, payment_type_counts.values, color='skyblue')  # Store the bar objects
plt.title('Payment Type Counts')
plt.xlabel('Payment Type')
plt.ylabel('Count')
plt.xticks(rotation=45, ha='right')

# Add labels to the bars
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.1, round(yval,2), ha='center', va='bottom', color='black', fontweight='bold')

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Assuming you have 'payment_type_counts' calculated

plt.figure(figsize=(8, 6))
payment_type_counts.plot(kind='pie', startangle=90, colors=['skyblue', 'lightcoral', 'lightgreen', 'gold'],
                        wedgeprops={'linewidth': 1, 'edgecolor': 'white'},
                        textprops={'fontsize': 8, 'color': 'black'})  # Reduced fontsize to 8
plt.title('Payment Type Distribution', fontsize=14)
plt.ylabel('')  # Remove the default ylabel
plt.tight_layout()
plt.show()

import pandas as pd

# Assuming your DataFrame is named 'payments'

def highlight_outliers(s, color, lower_limit, upper_limit): # Added lower_limit and upper_limit as parameters
    '''
    Highlight the outliers in a Series with the specified color.
    '''
    is_outlier = (s < lower_limit) | (s > upper_limit)  # condition for outliers
    return ['background-color: ' + color if v else '' for v in is_outlier]

# Calculate quantiles and limits for 'payment_value'
Q1_value = payments['payment_value'].quantile(0.25)
Q3_value = payments['payment_value'].quantile(0.75)
IQR_value = Q3_value - Q1_value
lower_limit_value = Q1_value - 1.5 * IQR_value
upper_limit_value = Q3_value + 1.5 * IQR_value

# Calculate quantiles and limits for 'payment_installments'
Q1_installments = payments['payment_installments'].quantile(0.25)
Q3_installments = payments['payment_installments'].quantile(0.75)
IQR_installments = Q3_installments - Q1_installments
lower_limit_installments = Q1_installments - 1.5 * IQR_installments
upper_limit_installments = Q3_installments + 1.5 * IQR_installments

# Apply styling
styled_payments = payments.style.apply(highlight_outliers, color='red', subset=['payment_value'], lower_limit=lower_limit_value, upper_limit=upper_limit_value) \
                           .apply(highlight_outliers, color='yellow', subset=['payment_installments'],
                                  lower_limit=lower_limit_installments, upper_limit=upper_limit_installments)

# Display the styled DataFrame
display(styled_payments)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming your DataFrame is named 'payments'

# Create a box plot for 'payment_value'
plt.figure(figsize=(8, 6))
sns.boxplot(x=payments['payment_value'])
plt.title('Box Plot of Payment Value with Outliers')
plt.xlabel('Payment Value')
plt.show()
# Print some information about the outliers
print(f"Number of outliers: {len(outliers)}")
print(f"Lower limit: {lower_limit}")
print(f"Upper limit: {upper_limit}")

# Create a box plot for 'payment_installments'
plt.figure(figsize=(8, 6))
sns.boxplot(x=payments['payment_installments'])
plt.title('Box Plot of Payment Installments with Outliers')
plt.xlabel('Payment Installments')
plt.show()
# Print some information about the outliers
print(f"Number of outliers: {len(outliers)}")
print(f"Lower limit: {lower_limit}")
print(f"Upper limit: {upper_limit}")

import pandas as pd

# Assuming you have 'customers', 'orders', and 'payments' DataFrames

# Merge orders and payments DataFrames on 'order_id'
merged_orders_payments = pd.merge(orders, payments, on='order_id', how='left')

# Merge the result with customers DataFrame on 'customer_id'
merged_data = pd.merge(merged_orders_payments, customers, on='customer_id', how='left')

# Filter for payments of 6000 or more
filtered_data = merged_data[merged_data['payment_value'] >= 6000]  # Changed to payment_value

# Get the number of unique customers
num_customers = filtered_data['customer_id'].nunique()

# Display the result
print(f"Number of customers who paid 6000 or more: {num_customers}") # Changed message

import pandas as pd

# Assuming you have 'customers', 'orders', and 'payments' DataFrames

# Merge orders and payments DataFrames on 'order_id'
merged_orders_payments = pd.merge(orders, payments, on='order_id', how='left')

# Merge the result with customers DataFrame on 'customer_id'
merged_data = pd.merge(merged_orders_payments, customers, on='customer_id', how='left')

# Filter for payments of 6000 or more
filtered_data = merged_data[merged_data['payment_value'] >= 6000]

# Select the desired columns including the new ones
result = filtered_data[['customer_id', 'customer_city', 'payment_type', 'order_id', 'payment_value', 'payment_installments']]

# Sort the result by payment_value descending and then payment_installments descending
result = result.sort_values(by=['payment_value', 'payment_installments'], ascending=[False, False])

# Highlight rows where payment_installments is 8
def highlight_installments(s):
    '''
    Highlight rows where payment_installments is 8 with a different color.
    '''
    is_eight = s == 8
    return ['background-color: yellow' if v else '' for v in is_eight]

styled_result = result.style.apply(highlight_installments, subset=['payment_installments'])

# Display the styled result
display(styled_result)

import pandas as pd

# Assuming you have 'customers', 'orders', and 'payments' DataFrames

# Merge orders and payments DataFrames on 'order_id'
merged_orders_payments = pd.merge(orders, payments, on='order_id', how='left')

# Merge the result with customers DataFrame on 'customer_id'
merged_data = pd.merge(merged_orders_payments, customers, on='customer_id', how='left')

# Filter for payments with installment over 20
filtered_data = merged_data[merged_data['payment_installments'] > 20]

# Get the number of unique customers
num_customers = filtered_data['customer_id'].nunique()

# Display the result
print(f"Number of customers with payment installment over 20: {num_customers}")

import pandas as pd

# Assuming you have 'customers', 'orders', and 'payments' DataFrames

# Merge orders and payments DataFrames on 'order_id'
merged_orders_payments = pd.merge(orders, payments, on='order_id', how='left')

# Merge the result with customers DataFrame on 'customer_id'
merged_data = pd.merge(merged_orders_payments, customers, on='customer_id', how='left')

# Filter for payments with installment equal to or over 20
filtered_data = merged_data[merged_data['payment_installments'] >= 20]

# Select the desired columns including the new ones
result = filtered_data[['customer_id', 'customer_city', 'payment_type', 'order_id', 'payment_value', 'payment_installments']]

# Sort the result by payment_installments descending
result = result.sort_values(by='payment_installments', ascending=False)

# Display the result
print(result)

"""## olist_order_reviews_dataset"""

# Import the pandas library with the alias 'pd'
import pandas as pd

# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„Ù
reviews = pd.read_csv("olist_order_reviews_dataset.csv")
print(reviews)

reviews.head()

reviews.describe()

reviews.shape

reviews.info()

reviews['review_creation_date'] = pd.to_datetime(reviews['review_creation_date'])
reviews['review_answer_timestamp'] = pd.to_datetime(reviews['review_answer_timestamp'])

reviews.info()

reviews.duplicated().sum()

reviews.isnull().sum()

import pandas as pd

# Assuming your DataFrame is named 'reviews'

# Calculate the percentage of null values in 'review_comment_title'
null_percentage = (reviews['review_comment_title'].isnull().sum() / len(reviews)) * 100

# Display the result
print(f"Percentage of null values in 'review_comment_title': {null_percentage:.2f}%")

import pandas as pd

# Assuming your DataFrame is named 'reviews'

# Calculate the percentage of null values in 'review_comment_message'
null_percentage = (reviews['review_comment_message'].isnull().sum() / len(reviews)) * 100

# Display the result
print(f"Percentage of null values in 'review_comment_message': {null_percentage:.2f}%")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming your DataFrame is named 'reviews'
# and the column you want to analyze is 'review_score'

# Calculate quantiles
Q1 = reviews['review_score'].quantile(0.25)
Q3 = reviews['review_score'].quantile(0.75)
IQR = Q3 - Q1

# Define upper and lower bounds for outliers
lower_limit = Q1 - 1.5 * IQR
upper_limit = Q3 + 1.5 * IQR

# Identify outliers
outliers = reviews[(reviews['review_score'] < lower_limit) | (reviews['review_score'] > upper_limit)]

# Create a box plot to visualize outliers
plt.figure(figsize=(8, 6))
sns.boxplot(x=reviews['review_score'])
plt.title('Box Plot of Review Score with Outliers')
plt.xlabel('Review Score')
plt.show()

# Print some information about the outliers
print(f"Number of outliers: {len(outliers)}")
print(f"Lower limit: {lower_limit}")
print(f"Upper limit: {upper_limit}")

import pandas as pd

# Assuming you have 'reviews', 'orders', and 'customers' DataFrames

# Merge reviews and orders DataFrames on 'order_id'
merged_reviews_orders = pd.merge(reviews, orders, on='order_id', how='left')

# Merge the result with customers DataFrame on 'customer_id'
merged_data = pd.merge(merged_reviews_orders, customers, on='customer_id', how='left')

# Filter for review scores between 1 and 2.5
filtered_data = merged_data[(merged_data['review_score'] >= 1) & (merged_data['review_score'] <= 2.5)]

# Calculate the number of customers with low review scores
num_low_review_customers = filtered_data['customer_unique_id'].nunique()  # Use customer_unique_id for unique customers

# Calculate the total number of customers
total_customers = customers['customer_unique_id'].nunique()  # Use customer_unique_id for unique customers

# Calculate the percentage of customers with low review scores
percentage = (num_low_review_customers / total_customers) * 100

# Display the results
print(f"Number of customers with review scores between 1 and 2.5: {num_low_review_customers}")
print(f"Percentage of customers with low review scores relative to total customers: {percentage:.2f}%")

import pandas as pd

# Assuming you have 'reviews', 'orders', and 'customers' DataFrames

# Merge reviews and orders DataFrames on 'order_id'
merged_reviews_orders = pd.merge(reviews, orders, on='order_id', how='left')

# Merge the result with customers DataFrame on 'customer_id'
merged_data = pd.merge(merged_reviews_orders, customers, on='customer_id', how='left')

# Filter for review scores between 1 and 3
filtered_data = merged_data[(merged_data['review_score'] >= 1) & (merged_data['review_score'] <= 2.5)]

# Select desired columns for customer and order information
result = filtered_data[['customer_id', 'customer_unique_id', 'customer_city', 'order_id', 'review_score']]

# Display the result
print(result)
result = filtered_data[['customer_id', 'customer_unique_id', 'customer_city', 'order_id', 'review_score']]

# Display the result
print(result)

"""## olist_products_dataset"""

# Import the pandas library with the alias 'pd'
import pandas as pd

# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„Ù
products = pd.read_csv("olist_products_dataset.csv")
print(products)

products.head()

products.describe()

products.shape

products.info()

products.duplicated().sum()

products.isnull().sum()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.preprocessing import LabelEncoder

# ğŸ“Œ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
products = pd.read_csv("olist_products_dataset.csv")

# ğŸ“Œ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤
features = ['product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']

# ğŸ“Œ Ø­Ø°Ù Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù…ÙÙ‚ÙˆØ¯Ø©
products = products.dropna(subset=features, how='all')

# ğŸ“Œ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ ÙƒÙ„ Ø¹Ù…ÙˆØ¯ Ù…ÙÙ‚ÙˆØ¯ Ø¹Ù„Ù‰ Ø­Ø¯Ø©
def fill_missing_values(target_column, is_categorical=False):
    """
    ØªØ¹ÙˆÙŠØ¶ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù… Ø¢Ù„ÙŠ.
    Ø¥Ø°Ø§ ÙƒØ§Ù† is_categorical=TrueØŒ Ù†Ø³ØªØ®Ø¯Ù… ØªØµÙ†ÙŠÙ (RandomForestClassifier)ØŒ ÙˆØ¥Ù„Ø§ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù†Ø­Ø¯Ø§Ø± (RandomForestRegressor).
    """
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø¬Ø²Ø¡ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙƒØ§Ù…Ù„Ø© ÙˆØ¬Ø²Ø¡ Ù…ÙÙ‚ÙˆØ¯
    products_train = products.dropna(subset=[target_column])
    products_missing = products[products[target_column].isna()]

    if is_categorical:
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Label Encoding
        le = LabelEncoder()
        products_train[target_column] = le.fit_transform(products_train[target_column])

    # ÙØµÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆØ§Ù„Ù‡Ø¯Ù
    X = products_train[features]
    y = products_train[target_column]

    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ø®ØªØ¨Ø§Ø± Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
    model = RandomForestClassifier(n_estimators=100, random_state=42) if is_categorical else RandomForestRegressor(n_estimators=100, random_state=42)

    # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    model.fit(X_train, y_train)

    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    accuracy = model.score(X_test, y_test) if is_categorical else model.score(X_test, y_test)
    print(f"ğŸ”¹ Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ {target_column}: {accuracy:.2%}")

    # ØªÙˆÙ‚Ø¹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
    predicted_values = model.predict(products_missing[features])

    if is_categorical:
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø¥Ù„Ù‰ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ©
        predicted_values = le.inverse_transform(predicted_values)

    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
    products.loc[products[target_column].isna(), target_column] = predicted_values


# ğŸ“Œ ØªØ¹ÙˆÙŠØ¶ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
fill_missing_values('product_category_name', is_categorical=True)
fill_missing_values('product_name_lenght')
fill_missing_values('product_description_lenght')
fill_missing_values('product_photos_qty')

# ğŸ“Œ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„
products.to_csv("olist_products_dataset_filled.csv", index=False)

print("âœ… ØªÙ… Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø¨Ù†Ø¬Ø§Ø­!")

from google.colab import files
files.download("olist_products_dataset_filled.csv")

# Import the pandas library with the alias 'pd'
import pandas as pd

# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„Ù
products.filled = pd.read_csv("olist_products_dataset_filled.csv")
print(products.filled)

products.filled.duplicated().sum()

products.filled.isnull().sum()

# Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø¨Ù€ "Unknown" Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¦ÙˆÙŠØ©
products[['product_name_lenght', 'product_description_lenght', 'product_photos_qty']] = \
    products[['product_name_lenght', 'product_description_lenght', 'product_photos_qty']].fillna("Unknown")

# Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„
print(products.isnull().sum())

products.to_csv("olist_products_dataset_final.csv", index=False)

from google.colab import files
files.download("olist_products_dataset_final.csv")

# Assuming you have already loaded the 'products' DataFrame

# Get the number of products (rows in the DataFrame)
num_products = len(products)

# Print the result
print(f"Number of products: {num_products}")

import pandas as pd

# Assuming you have already loaded the 'products' DataFrame

# Group products by category and count the number of products in each category
category_counts = products.groupby('product_category_name')['product_id'].count()

# Get the number of unique categories
num_categories = len(category_counts)

# Get the names of the unique categories
category_names = category_counts.index.tolist()

# Print the results
print(f"Number of unique categories: {num_categories}")
print("\nCategory Names:")
for name in category_names:
    print(name)

print("\nNumber of products in each category:")
print(category_counts)

import pandas as pd

# Assuming you have already loaded the 'products' DataFrame

# Group products by category and count the number of products in each category
category_counts = products.groupby('product_category_name')['product_id'].count()

# Get the top 10 categories with the most products
top_10_categories = category_counts.sort_values(ascending=False).head(10)

# Print the result
print("Top 10 Product Categories with Most Products:")
print(top_10_categories)

import pandas as pd
import matplotlib.pyplot as plt

# ... (previous code to calculate top_10_categories) ...

# Create a bar chart of the top 10 categories
plt.figure(figsize=(12, 6))  # Adjust figure size if needed
plt.bar(top_10_categories.index, top_10_categories.values)
plt.xlabel("Product Category")
plt.ylabel("Number of Products")
plt.title("Top 10 Product Categories with Most Products")
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability
plt.tight_layout()  # Adjust layout to prevent labels from overlapping
plt.show()



"""## olist_sellers_dataset"""

# Import the pandas library with the alias 'pd'
import pandas as pd
# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„Ù
sellers = pd.read_csv("olist_sellers_dataset.csv")
print(sellers)

sellers.head()

sellers.shape

sellers.describe()

sellers.info()

sellers.duplicated().sum()

sellers.isnull().sum()

# Assuming you have already loaded the 'sellers' DataFrame

# Get the number of unique seller IDs
num_unique_sellers = sellers['seller_id'].nunique()

# Get the number of unique seller cities
num_unique_cities = sellers['seller_city'].nunique()

# Get the number of unique seller states
num_unique_states = sellers['seller_state'].nunique()

# Print the results
print(f"Number of unique seller IDs: {num_unique_sellers}")
print(f"Number of unique seller cities: {num_unique_cities}")
print(f"Number of unique seller states: {num_unique_states}")

# Calculate the top 10 seller cities
top_10_cities = sellers['seller_city'].value_counts().head(10)

# Display the result
print("Top 10 Seller Cities:")
print(top_10_cities)

import matplotlib.pyplot as plt

# Calculate the top 10 customer cities
top_10_cities = sellers['seller_city'].value_counts().head(10)

# Create the horizontal bar chart
plt.figure(figsize=(12, 6))  # Set the figure size
plt.barh(top_10_cities.index, top_10_cities.values)  # Create the horizontal bar chart
plt.xlabel("Number of Sellers")  # Label the x-axis
plt.ylabel("City")  # Label the y-axis
plt.title("Top 10 Seller Cities")  # Set the title

# Add values to the bars (optional)
for i, v in enumerate(top_10_cities.values):
    plt.text(v + 3, i, str(v), color='black', fontweight='bold', va='center')

plt.tight_layout()  # Adjust the layout
plt.show()  # Display the chart

# Calculate the top 10 seller states
top_10_states = sellers['seller_state'].value_counts().head(10)

# Display the result
print("\nTop 10 Seller States:")
print(top_10_states)

import matplotlib.pyplot as plt

# Calculate the top 10 customer states
top_10_states = sellers['seller_state'].value_counts().head(10)

# Create the horizontal bar chart
plt.figure(figsize=(12, 6))  # Set the figure size
plt.barh(top_10_states.index, top_10_states.values)  # Create the horizontal bar chart
plt.xlabel("Number of Sellers")  # Label the x-axis
plt.ylabel("State")  # Label the y-axis
plt.title("Top 10 Seller States")  # Set the title

# Add values to the bars (optional)
for i, v in enumerate(top_10_states.values):
    plt.text(v + 3, i, str(v), color='black', fontweight='bold', va='center')

plt.tight_layout()  # Adjust the layout
plt.show()  # Display the chart

"""## **Advanced Analysis**"""

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd  # Make sure pandas is imported

# Merge 'orders' and 'payments' DataFrames on 'order_id'
merged_data = pd.merge(orders, payments, on='order_id', how='left')

# Convert 'order_purchase_timestamp' to datetime objects
merged_data['order_purchase_timestamp'] = pd.to_datetime(merged_data['order_purchase_timestamp'])

# Extract numerical features from the timestamp (e.g., hour, day, month)
# Here, we extract the hour of the day
merged_data['order_purchase_hour'] = merged_data['order_purchase_timestamp'].dt.hour

# Now you can calculate the correlation using the merged DataFrame with the new numerical feature
correlation_matrix = merged_data[['order_purchase_hour', 'payment_value']].corr()

# Visualize correlation using heatmap
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd  # Make sure pandas is imported

# Merge 'orders', 'payments', and 'items' DataFrames
merged_data = pd.merge(orders, payments, on='order_id', how='left')
merged_data = pd.merge(merged_data, items, on='order_id', how='left')

# Calculate order value (assuming it's the sum of price and freight_value)
merged_data['order_value'] = merged_data['price'] + merged_data['freight_value']

# Example: Distribution of order values using a histogram
sns.histplot(merged_data['order_value'], bins=20)
plt.title('Distribution of Order Values')
plt.xlabel('Order Value')
plt.ylabel('Frequency')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd  # Make sure pandas is imported

# Merge 'orders', 'payments', and 'items' DataFrames
merged_data = pd.merge(orders, payments, on='order_id', how='left')
merged_data = pd.merge(merged_data, items, on='order_id', how='left')
# Merge with 'reviews' DataFrame on 'order_id' to include 'review_score'
merged_data = pd.merge(merged_data, reviews, on='order_id', how='left') #This line was added

# Calculate order value (assuming it's the sum of price and freight_value)
merged_data['order_value'] = merged_data['price'] + merged_data['freight_value']


# Example: Correlation between product price and review score
correlation = merged_data['price'].corr(merged_data['review_score'])
print(f"Correlation between product price and review score: {correlation}")

import pandas as pd

# Example: Calculate Recency for each customer
customer_recency = orders.groupby('customer_id')['order_purchase_timestamp'].max().reset_index()
# Convert 'order_purchase_timestamp' to datetime if it's not already
customer_recency['order_purchase_timestamp'] = pd.to_datetime(customer_recency['order_purchase_timestamp'])
customer_recency['recency'] = (customer_recency['order_purchase_timestamp'].max() - customer_recency['order_purchase_timestamp']).dt.days

# Print the results
print(customer_recency[['customer_id', 'recency']])

import pandas as pd
import matplotlib.pyplot as plt

# Example: Calculate Recency for each customer
customer_recency = orders.groupby('customer_id')['order_purchase_timestamp'].max().reset_index()
# Convert 'order_purchase_timestamp' to datetime if it's not already
customer_recency['order_purchase_timestamp'] = pd.to_datetime(customer_recency['order_purchase_timestamp'])
customer_recency['recency'] = (customer_recency['order_purchase_timestamp'].max() - customer_recency['order_purchase_timestamp']).dt.days

# Sort by recency and get top 10 and bottom 10
top_10 = customer_recency.sort_values(by='recency', ascending=True).head(10)  # Lowest recency (most recent)
bottom_10 = customer_recency.sort_values(by='recency', ascending=False).head(10) # Highest recency (least recent)

# Create separate bar charts
plt.figure(figsize=(12, 6))

# Chart for top 10
plt.subplot(1, 2, 1)  # 1 row, 2 columns, first plot
plt.bar(top_10['customer_id'], top_10['recency'], color='skyblue')
plt.xlabel("Customer ID")
plt.ylabel("Recency (Days)")
plt.title("Top 10 Recency Values")
plt.xticks(rotation=45, ha='right')

# Chart for bottom 10
plt.subplot(1, 2, 2)  # 1 row, 2 columns, second plot
plt.bar(bottom_10['customer_id'], bottom_10['recency'], color='salmon')
plt.xlabel("Customer ID")
plt.ylabel("Recency (Days)")
plt.title("Bottom 10 Recency Values")
plt.xticks(rotation=45, ha='right')

plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# ... (your code for calculating customer_recency and top/bottom 10 customers) ...

# ğŸ“Œ Ensure 'product_category_name' is included in the merge:
merged_data = pd.merge(orders, items, on='order_id', how='left')
merged_data = pd.merge(merged_data, products[['product_id', 'product_category_name']], on='product_id', how='left')  # Explicitly include product_category_name
merged_data = pd.merge(merged_data, customers, on='customer_id', how='left')

# Filter data for top 10 and bottom 10 customers
top_10_data = merged_data[merged_data['customer_id'].isin(top_10['customer_id'])]  # Assuming top_10 has customer IDs
bottom_10_data = merged_data[merged_data['customer_id'].isin(bottom_10['customer_id'])]  # Assuming bottom_10 has customer IDs


# Group by customer location and product category, then count purchases
# For top 10 customers
top_10_product_counts = top_10_data.groupby(['customer_city', 'customer_state', 'product_category_name'])['product_id'].count().unstack(fill_value=0)
# For bottom 10 customers
bottom_10_product_counts = bottom_10_data.groupby(['customer_city', 'customer_state', 'product_category_name'])['product_id'].count().unstack(fill_value=0)

# Display the results
print("Top 10 Customers:")
display(top_10_product_counts)

print("\nBottom 10 Customers:")
display(bottom_10_product_counts)

import pandas as pd

# Assuming you have 'customers', 'orders', and 'items' DataFrames loaded

# Calculate Recency for each customer
customer_recency = orders.groupby('customer_id')['order_purchase_timestamp'].max().reset_index()
customer_recency['order_purchase_timestamp'] = pd.to_datetime(customer_recency['order_purchase_timestamp'])
customer_recency['recency'] = (customer_recency['order_purchase_timestamp'].max() - customer_recency['order_purchase_timestamp']).dt.days

# Sort by recency and get top 10 and bottom 10
top_10_recency = customer_recency.sort_values(by='recency', ascending=True).head(10)  # Lowest recency (most recent)
bottom_10_recency = customer_recency.sort_values(by='recency', ascending=False).head(10) # Highest recency (least recent)

# Merge with other DataFrames to get desired columns
top_10_result = pd.merge(top_10_recency[['customer_id', 'recency']],
                         customers[['customer_id', 'customer_city', 'customer_state']],
                         on='customer_id', how='left')
top_10_result = pd.merge(top_10_result, orders[['customer_id', 'order_id']], on='customer_id', how='left')
top_10_result = pd.merge(top_10_result, items[['order_id', 'product_id']], on='order_id', how='left')
top_10_result = pd.merge(top_10_result, products[['product_id', 'product_category_name']], on='product_id', how='left')


bottom_10_result = pd.merge(bottom_10_recency[['customer_id', 'recency']],
                            customers[['customer_id', 'customer_city', 'customer_state']],
                            on='customer_id', how='left')
bottom_10_result = pd.merge(bottom_10_result, orders[['customer_id', 'order_id']], on='customer_id', how='left')
bottom_10_result = pd.merge(bottom_10_result, items[['order_id', 'product_id']], on='order_id', how='left')
bottom_10_result = pd.merge(bottom_10_result, products[['product_id', 'product_category_name']], on='product_id', how='left')

# Display the results
print("Top 10 Customers by Recency:")
print(top_10_result[['customer_id', 'customer_city', 'customer_state', 'order_id', 'product_category_name', 'product_id', 'recency']])

print("\nBottom 10 Customers by Recency:")
print(bottom_10_result[['customer_id', 'customer_city', 'customer_state', 'order_id', 'product_category_name', 'product_id', 'recency']])